{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 6)\n",
      "(404288, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "dtype = {\n",
    "    'id': np.int8,\n",
    "    'qid1': np.int8,\n",
    "    'qid2': np.int8,\n",
    "    'question1': np.str,\n",
    "    'question2': np.str,\n",
    "    'is_duplicate': np.int8\n",
    "}\n",
    "train = pd.read_csv('/input/Kaggle/Quora/train.csv', dtype=dtype)\n",
    "print(train.shape)\n",
    "train.dropna(inplace=True)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "dtype = {\n",
    "    'test_id': np.int8,\n",
    "    'question1': np.str,\n",
    "    'question2': np.str\n",
    "}\n",
    "test = pd.read_csv('/input/Kaggle/Quora/test.csv', dtype=dtype)\n",
    "print( (test.isnull()).sum().sum() )\n",
    "test.replace(np.nan, '', inplace=True)\n",
    "print( (test.isnull()).sum().sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_refine</th>\n",
       "      <th>question2_refine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "\n",
       "                                    question1_refine  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                    question2_refine  \n",
       "0  What is the step by step guide to invest in sh...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 必要的\n",
    "def lower(q):\n",
    "    return q.lower()\n",
    "\n",
    "train['question1_refine'] = train['question1'].apply(lower)\n",
    "train['question2_refine'] = train['question2'].apply(lower)\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_refine</th>\n",
       "      <th>question2_refine</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_set_len</th>\n",
       "      <th>q2_set_len</th>\n",
       "      <th>common_len</th>\n",
       "      <th>common_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "\n",
       "                                    question1_refine  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "\n",
       "                                    question2_refine  q1_len  q2_len  \\\n",
       "0  what is the step by step guide to invest in sh...    14.0    12.0   \n",
       "\n",
       "   q1_set_len  q2_set_len  common_len  common_ratio  \n",
       "0        12.0        11.0        10.0      0.833333  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 结果验证这个不好，但从逻辑上，不好理解。可能是由于这样把很多的表单符号单独出来了，不过后面排除掉，还是效果欠佳\n",
    "import re\n",
    "\n",
    "pattern1 = re.compile(r'(?<=\\w)([\\?\\.,\\)])')\n",
    "pattern2 = re.compile(r'([\\(])(?=\\w)')\n",
    "\n",
    "def fill_blank(matched):\n",
    "    return ' {} '.format(matched.group(1))\n",
    "\n",
    "def leave_blank(q):\n",
    "    q = re.sub(pattern1, fill_blank, q)\n",
    "    q = re.sub(pattern2, fill_blank, q)\n",
    "    return q\n",
    "\n",
    "train['question1_refine'] = train['question1_refine'].apply(leave_blank)\n",
    "train['question2_refine'] = train['question2_refine'].apply(leave_blank)\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_refine</th>\n",
       "      <th>question2_refine</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_set_len</th>\n",
       "      <th>q2_set_len</th>\n",
       "      <th>common_len</th>\n",
       "      <th>common_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "\n",
       "                                    question1_refine  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "\n",
       "                                    question2_refine  q1_len  q2_len  \\\n",
       "0  what is the step by step guide to invest in sh...    14.0    12.0   \n",
       "\n",
       "   q1_set_len  q2_set_len  common_len  common_ratio  \n",
       "0        12.0        11.0        10.0      0.833333  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 经过测试，这个效果也不好\n",
    "import re\n",
    "\n",
    "remove_mark_pattern = re.compile(r'\\W')\n",
    "def remove_mark(q):\n",
    "    return re.sub(remove_mark_pattern, ' ', q)\n",
    "\n",
    "train['question1_refine'] = train['question1_refine'].apply(remove_mark)\n",
    "train['question2_refine'] = train['question2_refine'].apply(remove_mark)\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_refine</th>\n",
       "      <th>question2_refine</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>...</th>\n",
       "      <th>q1_start_with_can</th>\n",
       "      <th>q2_start_with_can</th>\n",
       "      <th>q1_start_with_should</th>\n",
       "      <th>q2_start_with_should</th>\n",
       "      <th>q1_start_with_will</th>\n",
       "      <th>q2_start_with_will</th>\n",
       "      <th>q1_start_with_is</th>\n",
       "      <th>q2_start_with_is</th>\n",
       "      <th>q1_start_with_do</th>\n",
       "      <th>q2_start_with_do</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "\n",
       "                                    question1_refine  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "\n",
       "                                    question2_refine  q1_len  q2_len  \\\n",
       "0  what is the step by step guide to invest in sh...    14.0    12.0   \n",
       "\n",
       "         ...         q1_start_with_can  q2_start_with_can  \\\n",
       "0        ...                         0                  0   \n",
       "\n",
       "   q1_start_with_should  q2_start_with_should  q1_start_with_will  \\\n",
       "0                     0                     0                   0   \n",
       "\n",
       "   q2_start_with_will  q1_start_with_is  q2_start_with_is  q1_start_with_do  \\\n",
       "0                   0                 0                 0                 0   \n",
       "\n",
       "   q2_start_with_do  \n",
       "0                 0  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 尝试过，结果还是不尽如人意\n",
    "def replace(q, replacements=()):\n",
    "    for f,t in replacements:\n",
    "        q = q.replace(f, t)\n",
    "    return q\n",
    "\n",
    "replacements = ((\"'s\", ''), ('\"', ''), (\"/\", ' '), (\"'m\", ' am'), (\"'ve\", ' have'), (\"'ll\", ' will'))\n",
    "train['question1_refine'] = train['question1_refine'].apply(replace, replacements=replacements)\n",
    "train['question2_refine'] = train['question2_refine'].apply(replace, replacements=replacements)\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "STOPWORDS = set(('i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn'))\n",
    "VOCAB_SET = set(word2vec.vocab.keys())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_refine</th>\n",
       "      <th>question2_refine</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_set_len</th>\n",
       "      <th>q2_set_len</th>\n",
       "      <th>common_len</th>\n",
       "      <th>common_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "\n",
       "                                    question1_refine  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                    question2_refine  q1_len  q2_len  \\\n",
       "0  What is the step by step guide to invest in sh...    14.0    12.0   \n",
       "\n",
       "   q1_set_len  q2_set_len  common_len  common_ratio  \n",
       "0        12.0        11.0        10.0      0.833333  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 结果验证有效果\n",
    "if False:\n",
    "    train.drop(['q1_len', 'q2_len', 'q1_set_len', 'q2_set_len', 'common_len', 'common_ratio'],\n",
    "              axis=1, inplace=True)\n",
    "SMOOTH = 1\n",
    "\n",
    "def word_count(row):\n",
    "    q1_list = row['question1_refine'].split()\n",
    "    q2_list = row['question2_refine'].split()\n",
    "    \n",
    "    q1_len = len(q1_list)\n",
    "    q2_len = len(q2_list)\n",
    "    \n",
    "    # set\n",
    "    q1_set = set(q1_list)\n",
    "    q2_set = set(q2_list)\n",
    "    common_set = q1_set.intersection(q2_set)\n",
    "    \n",
    "    q1_set_len = len(q1_set)\n",
    "    q2_set_len = len(q2_set)\n",
    "    common_len = len(common_set)\n",
    "    common_ratio = (2 * common_len) / (q1_set_len + q2_set_len + SMOOTH)\n",
    "    \n",
    "    return Series(data=(q1_len, q2_len, q1_set_len, q2_set_len, common_len, common_ratio),\n",
    "              index=['q1_len', 'q2_len', 'q1_set_len', 'q2_set_len', 'common_len', 'common_ratio'])\n",
    "\n",
    "    # 后面的部分尝试效果欠佳，虽然逻辑上好像符合\n",
    "#     q1_entity_set = (q1_set - STOPWORDS)#.intersection(VOCAB_SET)\n",
    "#     q2_entity_set = (q2_set - STOPWORDS)#.intersection(VOCAB_SET)\n",
    "#     q1_entity_set = q1_set.intersection(VOCAB_SET)\n",
    "#     q2_entity_set = q2_set.intersection(VOCAB_SET)\n",
    "#     entity_common_set = q1_entity_set.intersection(q2_entity_set)\n",
    "    \n",
    "#     # ns: non-stop\n",
    "#     q1_entity_len = len(q1_entity_set)\n",
    "#     q2_entity_len = len(q2_entity_set)\n",
    "#     entity_common_len = len(entity_common_set)\n",
    "#     entity_common_ratio = (2 * entity_common_len) / (q1_entity_len + q2_entity_len + SMOOTH)\n",
    "\n",
    "#     return Series(data=(q1_len, q2_len, q1_set_len, q2_set_len, common_len, common_ratio,\n",
    "#                         q1_entity_len, q2_entity_len, entity_common_len, entity_common_ratio),\n",
    "#                   index=['q1_len', 'q2_len', 'q1_set_len', 'q2_set_len', 'common_len', 'common_ratio',\n",
    "#                         'q1_entity_len', 'q2_entity_len', 'entity_common_len', 'entity_common_ratio'])\n",
    "\n",
    "word_counts = train.apply(word_count, axis=1)\n",
    "train = pd.concat([train, word_counts], axis=1)\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 经过验证，这个是有效果的\n",
    "from nltk.util import ngrams\n",
    "SMOOTH = 1\n",
    "\n",
    "def ngrams_count(row, n=2, suffix=''):\n",
    "    q1_ngrams = ngrams(row['question1_refine'].split(), n)\n",
    "    q2_ngrams = ngrams(row['question2_refine'].split(), n)\n",
    "    \n",
    "    q1_ngram_set = set([' '.join(tup) for tup in q1_ngrams])\n",
    "    q2_ngram_set = set([' '.join(tup) for tup in q2_ngrams])\n",
    "    common_set = q1_ngram_set.intersection(q2_ngram_set)\n",
    "    \n",
    "    q1_len = len(q1_ngram_set)\n",
    "    q2_len = len(q2_ngram_set)\n",
    "    common_len = len(common_set)\n",
    "    common_ratio = (2 * common_len) / (q1_len + q2_len + SMOOTH)\n",
    "    \n",
    "    return Series(data=(common_len, common_ratio),\n",
    "              index=['common_len'+suffix, 'common_ratio'+suffix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_refine</th>\n",
       "      <th>question2_refine</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_set_len</th>\n",
       "      <th>q2_set_len</th>\n",
       "      <th>common_len</th>\n",
       "      <th>common_ratio</th>\n",
       "      <th>common_len_2_grams</th>\n",
       "      <th>common_ratio_2_grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "\n",
       "                                    question1_refine  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "\n",
       "                                    question2_refine  q1_len  q2_len  \\\n",
       "0  what is the step by step guide to invest in sh...    14.0    12.0   \n",
       "\n",
       "   q1_set_len  q2_set_len  common_len  common_ratio  common_len_2_grams  \\\n",
       "0        12.0        11.0        10.0      0.833333                10.0   \n",
       "\n",
       "   common_ratio_2_grams  \n",
       "0                   0.8  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grams_2 = train.apply(ngrams_count, axis=1, n=2, suffix='_2_grams')\n",
    "train = pd.concat([train, grams_2], axis=1)\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_refine</th>\n",
       "      <th>question2_refine</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_set_len</th>\n",
       "      <th>q2_set_len</th>\n",
       "      <th>common_len</th>\n",
       "      <th>common_ratio</th>\n",
       "      <th>common_len_2_grams</th>\n",
       "      <th>common_ratio_2_grams</th>\n",
       "      <th>common_len_3_grams</th>\n",
       "      <th>common_ratio_3_grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "\n",
       "                                    question1_refine  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "\n",
       "                                    question2_refine  q1_len  q2_len  \\\n",
       "0  what is the step by step guide to invest in sh...    14.0    12.0   \n",
       "\n",
       "   q1_set_len  q2_set_len  common_len  common_ratio  common_len_2_grams  \\\n",
       "0        12.0        11.0        10.0      0.833333                10.0   \n",
       "\n",
       "   common_ratio_2_grams  common_len_3_grams  common_ratio_3_grams  \n",
       "0                   0.8                 9.0              0.782609  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grams_3 = train.apply(ngrams_count, axis=1, n=3, suffix='_3_grams')\n",
    "train = pd.concat([train, grams_3], axis=1)\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_refine</th>\n",
       "      <th>question2_refine</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>...</th>\n",
       "      <th>q1_start_with_can</th>\n",
       "      <th>q2_start_with_can</th>\n",
       "      <th>q1_start_with_should</th>\n",
       "      <th>q2_start_with_should</th>\n",
       "      <th>q1_start_with_will</th>\n",
       "      <th>q2_start_with_will</th>\n",
       "      <th>q1_start_with_is</th>\n",
       "      <th>q2_start_with_is</th>\n",
       "      <th>q1_start_with_do</th>\n",
       "      <th>q2_start_with_do</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "\n",
       "                                    question1_refine  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "\n",
       "                                    question2_refine  q1_len  q2_len  \\\n",
       "0  what is the step by step guide to invest in sh...    14.0    12.0   \n",
       "\n",
       "         ...         q1_start_with_can  q2_start_with_can  \\\n",
       "0        ...                         0                  0   \n",
       "\n",
       "   q1_start_with_should  q2_start_with_should  q1_start_with_will  \\\n",
       "0                     0                     0                   0   \n",
       "\n",
       "   q2_start_with_will  q1_start_with_is  q2_start_with_is  q1_start_with_do  \\\n",
       "0                   0                 0                 0                 0   \n",
       "\n",
       "   q2_start_with_do  \n",
       "0                 0  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 结果验证有效果\n",
    "def start_with(q, symbols):\n",
    "    s = q.split()\n",
    "    return int(s[0] in symbols) if len(s) > 0 else 0\n",
    "\n",
    "train['q1_start_with_what'] = train['question1_refine'].apply(start_with, symbols=('what', \"what's\"))\n",
    "train['q2_start_with_what'] = train['question2_refine'].apply(start_with, symbols=('what', \"what's\"))\n",
    "\n",
    "train['q1_start_with_how'] = train['question1_refine'].apply(start_with, symbols=('how'))\n",
    "train['q2_start_with_how'] = train['question2_refine'].apply(start_with, symbols=('how'))\n",
    "\n",
    "train['q1_start_with_why'] = train['question1_refine'].apply(start_with, symbols=('why'))\n",
    "train['q2_start_with_why'] = train['question2_refine'].apply(start_with, symbols=('why'))\n",
    "\n",
    "train['q1_start_with_who'] = train['question1_refine'].apply(start_with, symbols=('who'))\n",
    "train['q2_start_with_who'] = train['question2_refine'].apply(start_with, symbols=('who'))\n",
    "\n",
    "train['q1_start_with_where'] = train['question1_refine'].apply(start_with, symbols=('where'))\n",
    "train['q2_start_with_where'] = train['question2_refine'].apply(start_with, symbols=('where'))\n",
    "\n",
    "train['q1_start_with_when'] = train['question1_refine'].apply(start_with, symbols=('when'))\n",
    "train['q2_start_with_when'] = train['question2_refine'].apply(start_with, symbols=('when'))\n",
    "\n",
    "train['q1_start_with_which'] = train['question1_refine'].apply(start_with, symbols=('which'))\n",
    "train['q2_start_with_which'] = train['question2_refine'].apply(start_with, symbols=('which'))\n",
    "\n",
    "train['q1_start_with_can'] = train['question1_refine'].apply(start_with, symbols=('can', 'could'))\n",
    "train['q2_start_with_can'] = train['question2_refine'].apply(start_with, symbols=('can', 'could'))\n",
    "\n",
    "train['q1_start_with_should'] = train['question1_refine'].apply(start_with, symbols=('should'))\n",
    "train['q2_start_with_should'] = train['question2_refine'].apply(start_with, symbols=('should'))\n",
    "\n",
    "train['q1_start_with_will'] = train['question1_refine'].apply(start_with, symbols=('will', 'would'))\n",
    "train['q2_start_with_will'] = train['question2_refine'].apply(start_with, symbols=('will', 'would'))\n",
    "\n",
    "train['q1_start_with_is'] = train['question1_refine'].apply(start_with, symbols=('is', 'am', 'are'))\n",
    "train['q2_start_with_is'] = train['question2_refine'].apply(start_with, symbols=('is', 'am', 'are'))\n",
    "\n",
    "train['q1_start_with_do'] = train['question1_refine'].apply(start_with, symbols=('do', 'does', 'did'))\n",
    "train['q2_start_with_do'] = train['question2_refine'].apply(start_with, symbols=('do', 'does', 'did'))\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_refine</th>\n",
       "      <th>question2_refine</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>...</th>\n",
       "      <th>q1_start_with_should</th>\n",
       "      <th>q2_start_with_should</th>\n",
       "      <th>q1_start_with_will</th>\n",
       "      <th>q2_start_with_will</th>\n",
       "      <th>q1_start_with_is</th>\n",
       "      <th>q2_start_with_is</th>\n",
       "      <th>q1_start_with_do</th>\n",
       "      <th>q2_start_with_do</th>\n",
       "      <th>q1_has_question_mark</th>\n",
       "      <th>q2_has_question_mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "\n",
       "                                    question1_refine  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "\n",
       "                                    question2_refine  q1_len  q2_len  \\\n",
       "0  what is the step by step guide to invest in sh...    14.0    12.0   \n",
       "\n",
       "           ...           q1_start_with_should  q2_start_with_should  \\\n",
       "0          ...                              0                     0   \n",
       "\n",
       "   q1_start_with_will  q2_start_with_will  q1_start_with_is  q2_start_with_is  \\\n",
       "0                   0                   0                 0                 0   \n",
       "\n",
       "   q1_start_with_do  q2_start_with_do  q1_has_question_mark  \\\n",
       "0                 0                 0                     1   \n",
       "\n",
       "   q2_has_question_mark  \n",
       "0                     1  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最终验证没有效果\n",
    "# train.drop(['q1_has_question_mark', 'q2_has_question_mark'], axis=1, inplace=True)\n",
    "\n",
    "def has_symbol(q, symbol):\n",
    "    return 1 if symbol in q else 0\n",
    "\n",
    "train['q1_has_question_mark'] = train['question1_refine'].apply(has_symbol, symbol='?')\n",
    "train['q2_has_question_mark'] = train['question2_refine'].apply(has_symbol, symbol='?')\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 辅助Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec, KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('/input/Kaggle/Word2Vec/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_words = {}\n",
    "\n",
    "for q in train['question1_refine']:\n",
    "    s = q.split()\n",
    "    for word in s:\n",
    "        if word in unique_words:\n",
    "            unique_words[word] += 1\n",
    "        else:\n",
    "            unique_words[word] = 1\n",
    "\n",
    "for q in train['question2_refine']:\n",
    "    s = q.split()\n",
    "    for word in s:\n",
    "        if word in unique_words:\n",
    "            unique_words[word] += 1\n",
    "        else:\n",
    "            unique_words[word] = 1\n",
    "            \n",
    "unique_words_list = [ (v,k) for k,v in unique_words.items() ]\n",
    "unique_words_list = sorted(unique_words_list, reverse=True)\n",
    "\n",
    "rare_word_list = []\n",
    "\n",
    "for freq, word in unique_words_list:\n",
    "    if word not in word2vec.vocab:\n",
    "        rare_word_list.append((freq, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(841173, '?'),\n",
       " (376550, 'the'),\n",
       " (311497, 'what'),\n",
       " (269535, 'is'),\n",
       " (220398, 'how'),\n",
       " (214430, 'i'),\n",
       " (211154, 'a'),\n",
       " (205263, 'to'),\n",
       " (196454, 'in'),\n",
       " (160811, 'do'),\n",
       " (159720, 'of'),\n",
       " (145692, 'are'),\n",
       " (133192, 'and'),\n",
       " (114003, 'can'),\n",
       " (104343, 'for'),\n",
       " (100283, ','),\n",
       " (88922, 'you'),\n",
       " (83681, 'why'),\n",
       " (71511, '.'),\n",
       " (70838, 'my'),\n",
       " (70363, 'best'),\n",
       " (68830, 'it'),\n",
       " (60447, 'on'),\n",
       " (56318, 'does'),\n",
       " (44005, 'or'),\n",
       " (43931, 'which'),\n",
       " (43722, 'be'),\n",
       " (43674, 'if'),\n",
       " (41670, 'some'),\n",
       " (40753, 'have'),\n",
       " (40365, 'that'),\n",
       " (39673, 'with'),\n",
       " (39476, 'get'),\n",
       " (38976, 'should'),\n",
       " (36899, 'an'),\n",
       " (35214, 'from'),\n",
       " (33872, 'your'),\n",
       " (28320, 'india'),\n",
       " (28173, 'will'),\n",
       " (26149, 'when'),\n",
       " (25969, 'people'),\n",
       " (25564, 'who'),\n",
       " (25444, 'like'),\n",
       " (24983, '('),\n",
       " (24964, 'at'),\n",
       " (24893, ')'),\n",
       " (24659, 'good'),\n",
       " (23531, 'would'),\n",
       " (23337, 'there'),\n",
       " (22593, 'as'),\n",
       " (21131, 'about'),\n",
       " (20332, 'not'),\n",
       " (20266, 'between'),\n",
       " (19177, 'one'),\n",
       " (18890, 'most'),\n",
       " (18254, 'we'),\n",
       " (18108, 'make'),\n",
       " (18035, 'way'),\n",
       " (17878, 'did'),\n",
       " (17854, 'quora'),\n",
       " (17294, 'where'),\n",
       " (17219, 'by'),\n",
       " (16851, 'any'),\n",
       " (16447, 'was'),\n",
       " (16342, 'me'),\n",
       " (15782, 'so'),\n",
       " (15318, 'life'),\n",
       " (15101, 'after'),\n",
       " (14808, 'this'),\n",
       " (14790, 'they'),\n",
       " (14492, 'money'),\n",
       " (14221, 'time'),\n",
       " (13689, 'know'),\n",
       " (13379, 'difference'),\n",
       " (13265, 'has'),\n",
       " (12981, 'learn'),\n",
       " (12704, 'am'),\n",
       " (12373, 'new'),\n",
       " (12342, \"what's\"),\n",
       " (12340, 'much'),\n",
       " (12316, 'use'),\n",
       " (11771, 'their'),\n",
       " (11477, 'think'),\n",
       " (11442, 'many'),\n",
       " (10906, 'all'),\n",
       " (10686, 'indian'),\n",
       " (10627, 'someone'),\n",
       " (10617, 'than'),\n",
       " (10566, 'ever'),\n",
       " (10542, 'more'),\n",
       " (10517, 'find'),\n",
       " (10434, 'work'),\n",
       " (10015, 'without'),\n",
       " (9910, 'become'),\n",
       " (9892, 'but'),\n",
       " (9679, 'start'),\n",
       " (9679, 'online'),\n",
       " (9650, 'trump'),\n",
       " (9611, 'other'),\n",
       " (9431, 'world'),\n",
       " (9351, 'out'),\n",
       " (9341, 'want'),\n",
       " (9303, 'first'),\n",
       " (9056, 'better'),\n",
       " (8674, 'mean'),\n",
       " (8630, 'job'),\n",
       " (8358, 'english'),\n",
       " (8214, 'into'),\n",
       " (8205, 'us'),\n",
       " (8050, 'year'),\n",
       " (8003, \"don't\"),\n",
       " (7979, 'feel'),\n",
       " (7844, 'could'),\n",
       " (7790, 'up'),\n",
       " (7771, 'love'),\n",
       " (7765, 'take'),\n",
       " (7720, 'possible'),\n",
       " (7554, '2016'),\n",
       " (7356, 'he'),\n",
       " (7356, 'day'),\n",
       " (7237, 'things'),\n",
       " (7215, 'questions'),\n",
       " (7113, 'go'),\n",
       " (7105, 'notes'),\n",
       " (6977, 'phone'),\n",
       " (6910, 'ways'),\n",
       " (6907, 'really'),\n",
       " (6900, 'were'),\n",
       " (6838, 'buy'),\n",
       " (6814, 'weight'),\n",
       " (6807, 'account'),\n",
       " (6806, 'engineering'),\n",
       " (6777, 'used'),\n",
       " (6715, 'donald'),\n",
       " (6657, '500'),\n",
       " (6589, 'person'),\n",
       " (6517, 'them'),\n",
       " (6428, '1000'),\n",
       " (6358, 'long'),\n",
       " (6285, 'girl'),\n",
       " (6282, 'number'),\n",
       " (6250, 'being'),\n",
       " (6215, 'improve'),\n",
       " (6193, \"i'm\"),\n",
       " (6158, 'google'),\n",
       " (6151, 'using'),\n",
       " (5983, '2'),\n",
       " (5980, 'need'),\n",
       " (5905, 'business'),\n",
       " (5844, 'facebook'),\n",
       " (5843, 'lose'),\n",
       " (5839, 'books'),\n",
       " (5837, 'language'),\n",
       " (5802, 'stop'),\n",
       " (5755, 'sex'),\n",
       " (5751, 'old'),\n",
       " (5750, 'her'),\n",
       " (5718, 'different'),\n",
       " (5713, 'movie'),\n",
       " (5689, 'thing'),\n",
       " (5666, 'his'),\n",
       " (5574, 'been'),\n",
       " (5508, 'black'),\n",
       " (5456, 'book'),\n",
       " (5449, 'now'),\n",
       " (5433, 'just'),\n",
       " (5409, 'compare'),\n",
       " (5408, 'war'),\n",
       " (5397, 'see'),\n",
       " (5369, 'years'),\n",
       " (5356, 'free'),\n",
       " (5333, 'going'),\n",
       " (5280, 'still'),\n",
       " (5218, 'question'),\n",
       " (5218, 'programming'),\n",
       " (5148, 'no'),\n",
       " (5130, '1'),\n",
       " (5127, '3'),\n",
       " (5077, 'instagram'),\n",
       " (5065, 'only'),\n",
       " (5062, 'had'),\n",
       " (5026, 'change'),\n",
       " (5022, 'happen'),\n",
       " (5021, 'its'),\n",
       " (5004, 'help'),\n",
       " (4989, 'before'),\n",
       " (4970, 'movies'),\n",
       " (4892, 'company'),\n",
       " (4880, 'app'),\n",
       " (4873, 'president'),\n",
       " (4794, 'prepare'),\n",
       " (4790, 'college'),\n",
       " (4709, 'women'),\n",
       " (4700, 'under'),\n",
       " (4699, 'examples'),\n",
       " (4688, 'android'),\n",
       " (4679, 'over'),\n",
       " (4621, 'real'),\n",
       " (4600, 'computer'),\n",
       " (4569, 'while'),\n",
       " (4534, '5'),\n",
       " (4521, 'ask'),\n",
       " (4520, 'rs'),\n",
       " (4509, 'live'),\n",
       " (4495, 'website'),\n",
       " (4452, 'iphone'),\n",
       " (4446, 'country'),\n",
       " (4436, 'back'),\n",
       " (4411, 'important'),\n",
       " (4408, 'system'),\n",
       " (4406, 'our'),\n",
       " (4390, 'data'),\n",
       " (4378, 'learning'),\n",
       " (4333, 'bad'),\n",
       " (4329, 'win'),\n",
       " (4283, 'she'),\n",
       " (4248, 'increase'),\n",
       " (4232, 'hillary'),\n",
       " (4221, 'through'),\n",
       " (4219, 'study'),\n",
       " (4203, 'same'),\n",
       " (4191, 'made'),\n",
       " (4153, 'top'),\n",
       " (4088, 'school'),\n",
       " (4073, 'clinton'),\n",
       " (4064, 'science'),\n",
       " (4011, 'read'),\n",
       " (4004, 'software'),\n",
       " (3990, 'earn'),\n",
       " (3979, 'during'),\n",
       " (3956, 'two'),\n",
       " (3952, 'card'),\n",
       " (3951, 'water'),\n",
       " (3837, '&'),\n",
       " (3829, '10'),\n",
       " (3818, 'student'),\n",
       " (3794, 'government'),\n",
       " (3781, \"can't\"),\n",
       " (3769, 'say'),\n",
       " (3763, 's'),\n",
       " (3758, 'exam'),\n",
       " (3747, 'mobile'),\n",
       " (3713, 'car'),\n",
       " (3699, 'give'),\n",
       " (3693, 'name'),\n",
       " (3675, 'energy'),\n",
       " (3672, 'anyone'),\n",
       " (3665, 'getting'),\n",
       " (3641, 'word'),\n",
       " (3607, 'university'),\n",
       " (3582, 'high'),\n",
       " (3571, 'men'),\n",
       " (3519, 'companies'),\n",
       " (3479, 'true'),\n",
       " (3444, 'com'),\n",
       " (3420, 'average'),\n",
       " (3411, 'then'),\n",
       " (3401, 'days'),\n",
       " (3384, 'doing'),\n",
       " (3367, 'come'),\n",
       " (3355, 'laptop'),\n",
       " (3353, 'right'),\n",
       " (3349, 'career'),\n",
       " (3341, 'home'),\n",
       " (3340, 'earth'),\n",
       " (3332, 'even'),\n",
       " (3322, 'hair'),\n",
       " (3297, 'china'),\n",
       " (3288, 'web'),\n",
       " (3274, 'interview'),\n",
       " (3272, '2017'),\n",
       " (3269, 'look'),\n",
       " (3263, 'tell'),\n",
       " (3254, 'own'),\n",
       " (3240, 'social'),\n",
       " (3235, 'video'),\n",
       " (3222, 'answer'),\n",
       " (3217, '4'),\n",
       " (3212, 'travel'),\n",
       " (3208, 'bank'),\n",
       " (3179, 'meaning'),\n",
       " (3171, 'write'),\n",
       " (3170, 'safe'),\n",
       " (3136, 'youtube'),\n",
       " (3124, 'guy'),\n",
       " (3121, 'usa'),\n",
       " (3120, 'watch'),\n",
       " (3112, 'him'),\n",
       " (3111, 'students'),\n",
       " (3103, 'friend'),\n",
       " (3091, 'friends'),\n",
       " (3086, 'password'),\n",
       " (3062, 'done'),\n",
       " (3057, 'cost'),\n",
       " (3050, 'rupee'),\n",
       " (3045, 'eat'),\n",
       " (3036, 'happens'),\n",
       " (3030, 'relationship'),\n",
       " (3016, 'place'),\n",
       " (3014, 'rid'),\n",
       " (3010, 'working'),\n",
       " (3008, 'experience'),\n",
       " (2995, 'very'),\n",
       " (2988, 'having'),\n",
       " (2973, 'pakistan'),\n",
       " (2970, \"doesn't\"),\n",
       " (2967, 'girls'),\n",
       " (2953, 'big'),\n",
       " (2945, 'u'),\n",
       " (2942, 'food'),\n",
       " (2934, 'tv'),\n",
       " (2928, 'man'),\n",
       " (2924, 'game'),\n",
       " (2887, 'play'),\n",
       " (2885, 'favorite'),\n",
       " (2874, 'human'),\n",
       " (2865, 'service'),\n",
       " (2865, 'countries'),\n",
       " (2860, 'major'),\n",
       " (2840, 'whatsapp'),\n",
       " (2834, 'employees'),\n",
       " (2828, 'future'),\n",
       " (2803, 'history'),\n",
       " (2799, 'off'),\n",
       " (2780, 'affect'),\n",
       " (2763, 'b'),\n",
       " (2747, 'download'),\n",
       " (2740, 'believe'),\n",
       " (2734, 'process'),\n",
       " (2709, 'myself'),\n",
       " (2707, 'tips'),\n",
       " (2702, 'skills'),\n",
       " (2699, 'too'),\n",
       " (2694, 'effects'),\n",
       " (2693, 'every'),\n",
       " (2692, 'exist'),\n",
       " (2688, 'engineer'),\n",
       " (2673, 'tech'),\n",
       " (2668, 'last'),\n",
       " (2668, 'age'),\n",
       " (2667, 'state'),\n",
       " (2654, 'next'),\n",
       " (2654, 'email'),\n",
       " (2652, 'against'),\n",
       " (2651, 'election'),\n",
       " (2650, 'great'),\n",
       " (2648, 'chinese'),\n",
       " (2645, 'body'),\n",
       " (2644, 'support'),\n",
       " (2633, 'test'),\n",
       " (2632, 'java'),\n",
       " (2629, 'create'),\n",
       " (2626, 'mechanical'),\n",
       " (2621, 'differences'),\n",
       " (2620, 'white'),\n",
       " (2619, 'marketing'),\n",
       " (2597, 'places'),\n",
       " (2595, 'makes'),\n",
       " (2567, 'got'),\n",
       " (2551, 'internet'),\n",
       " (2548, 'interesting'),\n",
       " (2542, 'class'),\n",
       " (2540, 'hard'),\n",
       " (2534, 'police'),\n",
       " (2523, 'making'),\n",
       " (2518, 'states'),\n",
       " (2502, 'visit'),\n",
       " (2496, 'united'),\n",
       " (2482, 'end'),\n",
       " (2467, 'these'),\n",
       " (2464, 'delhi'),\n",
       " (2462, 'worth'),\n",
       " (2462, 'windows'),\n",
       " (2458, 'music'),\n",
       " (2442, 'american'),\n",
       " (2440, 'pay'),\n",
       " (2437, 'god'),\n",
       " (2430, 'month'),\n",
       " (2427, 'keep'),\n",
       " (2426, 'power'),\n",
       " (2422, 'never'),\n",
       " (2420, 'market'),\n",
       " (2410, '6'),\n",
       " (2401, 'salary'),\n",
       " (2390, '7'),\n",
       " (2388, 'song'),\n",
       " (2383, 'each'),\n",
       " (2382, 'actually'),\n",
       " (2366, 'around'),\n",
       " (2357, 'control'),\n",
       " (2328, 'girlfriend'),\n",
       " (2322, 'course'),\n",
       " (2313, 'culture'),\n",
       " (2307, 'available'),\n",
       " (2304, 'answers'),\n",
       " (2288, 'considered'),\n",
       " (2288, 'always'),\n",
       " (2287, 'gmail'),\n",
       " (2274, 'fat'),\n",
       " (2272, 'something'),\n",
       " (2272, 'code'),\n",
       " (2268, 'series'),\n",
       " (2256, 'another'),\n",
       " (2251, 'looking'),\n",
       " (2250, 'hotel'),\n",
       " (2238, 'common'),\n",
       " (2233, 'economy'),\n",
       " (2228, 'months'),\n",
       " (2224, 'woman'),\n",
       " (2222, 'apply'),\n",
       " (2219, 'writing'),\n",
       " (2218, 'delete'),\n",
       " (2211, 'c'),\n",
       " (2207, 'america'),\n",
       " (2199, 'modi'),\n",
       " (2197, 'universities'),\n",
       " (2195, 'mind'),\n",
       " (2194, 'light'),\n",
       " (2192, 'die'),\n",
       " (2191, 'development'),\n",
       " (2175, 'site'),\n",
       " (2156, 'jobs'),\n",
       " (2152, \"you've\"),\n",
       " (2151, 'parents'),\n",
       " (2146, 'per'),\n",
       " (2142, 'mba'),\n",
       " (2138, 'happened'),\n",
       " (2124, 'such'),\n",
       " (2117, 'score'),\n",
       " (2111, 'deal'),\n",
       " (2101, 'idea'),\n",
       " (2091, 'problem'),\n",
       " (2088, 'services'),\n",
       " (2087, 'kind'),\n",
       " (2085, 'universe'),\n",
       " (2084, 'review'),\n",
       " (2076, 'behind'),\n",
       " (2072, 'speed'),\n",
       " (2072, 'build'),\n",
       " (2061, 'cat'),\n",
       " (2057, 'open'),\n",
       " (2054, 'hack'),\n",
       " (2051, 'worst'),\n",
       " (2050, 'type'),\n",
       " (2050, 'show'),\n",
       " (2038, 'songs'),\n",
       " (2038, 'purpose'),\n",
       " (2036, 'bangalore'),\n",
       " (2034, 'note'),\n",
       " (2028, 'able'),\n",
       " (2019, 'period'),\n",
       " (2019, 'list'),\n",
       " (2011, 'living'),\n",
       " (2010, 'presidential'),\n",
       " (2008, 'design'),\n",
       " (2008, 'because'),\n",
       " (2004, 'differ'),\n",
       " (2001, 'near'),\n",
       " (1998, 'reduce'),\n",
       " (1990, 'cause'),\n",
       " (1989, 'reason'),\n",
       " (1988, 'games'),\n",
       " (1982, 'education'),\n",
       " (1980, 'instead'),\n",
       " (1976, 'digital'),\n",
       " (1973, 'wrong'),\n",
       " (1971, 'today'),\n",
       " (1971, 'majors'),\n",
       " (1971, 'civil'),\n",
       " (1969, 'private'),\n",
       " (1966, 'date'),\n",
       " (1966, 'asked'),\n",
       " (1965, 'current'),\n",
       " (1964, 'run'),\n",
       " (1963, 'join'),\n",
       " (1957, 'seen'),\n",
       " (1954, 'height'),\n",
       " (1951, 'popular'),\n",
       " (1946, 'space'),\n",
       " (1941, 'family'),\n",
       " (1939, 'degree'),\n",
       " (1935, 'easily'),\n",
       " (1932, 'websites'),\n",
       " (1930, 'call'),\n",
       " (1926, 'management'),\n",
       " (1919, 'program'),\n",
       " (1911, 'technology'),\n",
       " (1903, 'traffic'),\n",
       " (1903, 'international'),\n",
       " (1903, '8'),\n",
       " (1893, 'law'),\n",
       " (1891, 'dark'),\n",
       " (1888, 'biggest'),\n",
       " (1886, 'apps'),\n",
       " (1885, 'hate'),\n",
       " (1883, 'facts'),\n",
       " (1881, 'sentence'),\n",
       " (1875, 'order'),\n",
       " (1874, 'pregnant'),\n",
       " (1872, 'sleep')]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_list[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(841173, '?'),\n",
       " (211154, 'a'),\n",
       " (205263, 'to'),\n",
       " (159720, 'of'),\n",
       " (133192, 'and'),\n",
       " (100283, ','),\n",
       " (71511, '.'),\n",
       " (24983, '('),\n",
       " (24893, ')'),\n",
       " (17854, 'quora'),\n",
       " (7554, '2016'),\n",
       " (6657, '500'),\n",
       " (6428, '1000'),\n",
       " (6193, \"i'm\"),\n",
       " (5077, 'instagram'),\n",
       " (3829, '10'),\n",
       " (3272, '2017'),\n",
       " (2840, 'whatsapp'),\n",
       " (1818, '2000'),\n",
       " (1613, '000'),\n",
       " (1597, 'snapchat'),\n",
       " (1590, '-'),\n",
       " (1419, '2015'),\n",
       " (1351, \"someone's\"),\n",
       " (1333, ':'),\n",
       " (1300, 'jio'),\n",
       " (1250, '\"'),\n",
       " (1236, '20'),\n",
       " (1161, 'narendra'),\n",
       " (1156, '12'),\n",
       " (1103, 'nra'),\n",
       " (1076, '30'),\n",
       " (1057, '15'),\n",
       " (1037, '/'),\n",
       " (1025, \"i've\"),\n",
       " (995, '100'),\n",
       " (943, 'favourite'),\n",
       " (858, '16'),\n",
       " (857, 'upsc'),\n",
       " (856, 'pokémon'),\n",
       " (840, 'sbi'),\n",
       " (839, \"trump's\"),\n",
       " (778, '12th'),\n",
       " (773, '50'),\n",
       " (773, '\"the'),\n",
       " (738, '18'),\n",
       " (726, 'spotify'),\n",
       " (709, '2014'),\n",
       " (696, 'work-life'),\n",
       " (669, '13'),\n",
       " (667, 'mind-blowing'),\n",
       " (658, 'tcs'),\n",
       " (655, 'and/or'),\n",
       " (644, '14'),\n",
       " (637, \"india's\"),\n",
       " (635, '25'),\n",
       " (625, 'mbbs'),\n",
       " (616, '11'),\n",
       " (612, 'cgl'),\n",
       " (601, 'c++?'),\n",
       " (600, 'kvpy'),\n",
       " (574, 'c++'),\n",
       " (566, 'cambodia'),\n",
       " (563, 'better:'),\n",
       " (547, '24'),\n",
       " (534, '17'),\n",
       " (523, 'gmat'),\n",
       " (507, '\"i'),\n",
       " (497, 'mistry'),\n",
       " (488, \"clinton's\"),\n",
       " (480, \"modi's\"),\n",
       " (476, '21'),\n",
       " (458, '40'),\n",
       " (456, 'hill-station'),\n",
       " (456, 'ece'),\n",
       " (450, '15000'),\n",
       " (439, 'ibps'),\n",
       " (428, 'colour'),\n",
       " (423, 'redmi'),\n",
       " (421, 'iim'),\n",
       " (406, 'kejriwal'),\n",
       " (394, '2013'),\n",
       " (393, '10th'),\n",
       " (388, 'e-commerce'),\n",
       " (384, 'cgpa'),\n",
       " (382, 'ielts'),\n",
       " (374, 'centre'),\n",
       " (374, '15k'),\n",
       " (371, 'his/her'),\n",
       " (366, 'flipkart'),\n",
       " (360, 'wi-fi'),\n",
       " (358, 'what’s'),\n",
       " (353, '19'),\n",
       " (352, 'btech'),\n",
       " (343, 'bitcoin'),\n",
       " (339, 'paytm'),\n",
       " (337, 'accenture'),\n",
       " (333, 'elon'),\n",
       " (331, '200'),\n",
       " (330, 'demonetisation'),\n",
       " (327, 'india:'),\n",
       " (326, 'iits'),\n",
       " (326, 'arvind'),\n",
       " (325, '22'),\n",
       " (324, 'travelling'),\n",
       " (316, 'h1b'),\n",
       " (309, 'brexit'),\n",
       " (303, 'ps4'),\n",
       " (299, 'don’t'),\n",
       " (299, '23'),\n",
       " (298, 'arnab'),\n",
       " (294, 'manaphy'),\n",
       " (294, 'goswami'),\n",
       " (288, 'ek:'),\n",
       " (283, 'demonetize'),\n",
       " (282, '60'),\n",
       " (276, 'xiaomi'),\n",
       " (276, 'first-time'),\n",
       " (274, 'he/she'),\n",
       " (272, '₹500'),\n",
       " (268, 'upvotes'),\n",
       " (268, 'hadoop'),\n",
       " (264, 'enfield'),\n",
       " (263, '₹1000'),\n",
       " (260, '2012'),\n",
       " (257, 'officejet'),\n",
       " (256, 'grey'),\n",
       " (254, 'airprint'),\n",
       " (254, '4620'),\n",
       " (254, '2020'),\n",
       " (245, 'irctc'),\n",
       " (245, 'chhattisgarh'),\n",
       " (245, '2010'),\n",
       " (242, '\"?'),\n",
       " (238, \"person's\"),\n",
       " (237, 'mahabharata'),\n",
       " (235, '11th'),\n",
       " (234, '300'),\n",
       " (232, 'iims'),\n",
       " (232, '32'),\n",
       " (232, '2018'),\n",
       " (230, 'c#?'),\n",
       " (229, '$1'),\n",
       " (228, 'ugc'),\n",
       " (220, 'obc'),\n",
       " (219, \"earth's\"),\n",
       " (219, '30k'),\n",
       " (218, 'quorans'),\n",
       " (214, '60000'),\n",
       " (214, '21st'),\n",
       " (211, 'wwii'),\n",
       " (210, 'manipal'),\n",
       " (210, '\"why'),\n",
       " (209, 'bba'),\n",
       " (207, 'aiims'),\n",
       " (206, '9/11'),\n",
       " (204, 'isro'),\n",
       " (203, 'ncr'),\n",
       " (202, 'airbnb'),\n",
       " (202, '10k'),\n",
       " (201, '100%'),\n",
       " (198, '$100'),\n",
       " (197, '26'),\n",
       " (195, 'i’m'),\n",
       " (195, \"government's\"),\n",
       " (195, '28'),\n",
       " (194, '27'),\n",
       " (192, 'imei'),\n",
       " (191, 'ww1'),\n",
       " (187, 'mtech'),\n",
       " (186, 'at&t'),\n",
       " (183, 'toefl'),\n",
       " (182, 'lesser-known'),\n",
       " (182, '60k'),\n",
       " (181, 'balaji'),\n",
       " (180, \"friend's\"),\n",
       " (178, 'you\"?'),\n",
       " (177, '50k'),\n",
       " (174, 'icse'),\n",
       " (174, 'bhopal'),\n",
       " (173, \"quora's\"),\n",
       " (172, 'you\"'),\n",
       " (171, '35'),\n",
       " (171, '20s'),\n",
       " (171, ')?'),\n",
       " (170, '2011'),\n",
       " (167, 'demonetizing'),\n",
       " (167, 'c#'),\n",
       " (165, 'it’s'),\n",
       " (164, 'bengaluru'),\n",
       " (164, '\"you'),\n",
       " (163, 'aadhaar'),\n",
       " (160, 'wechat'),\n",
       " (159, 'icici'),\n",
       " (158, '360'),\n",
       " (157, 'pilani'),\n",
       " (157, \"google's\"),\n",
       " (156, 'vlsi'),\n",
       " (156, \"cities'\"),\n",
       " (156, '2019'),\n",
       " (156, '10000'),\n",
       " (156, '\"a'),\n",
       " (154, 'ipcc'),\n",
       " (153, 'mnc'),\n",
       " (153, '[math]'),\n",
       " (153, '150'),\n",
       " (152, 'iiit'),\n",
       " (151, '2-3'),\n",
       " (150, 'upvoted'),\n",
       " (150, 'minecraft'),\n",
       " (149, 'arduino'),\n",
       " (148, 'start-up'),\n",
       " (148, \"obama's\"),\n",
       " (147, '29'),\n",
       " (147, '25000'),\n",
       " (147, '2002'),\n",
       " (147, '..'),\n",
       " (146, 'cpec'),\n",
       " (146, '$10'),\n",
       " (144, 'zuckerberg'),\n",
       " (144, 'coursera'),\n",
       " (143, 'omegle'),\n",
       " (142, '90'),\n",
       " (141, 'ww3'),\n",
       " (141, 'deloitte'),\n",
       " (141, '\"how'),\n",
       " (140, 'can’t'),\n",
       " (140, '99'),\n",
       " (140, '51'),\n",
       " (139, 'life:'),\n",
       " (139, 'adolf'),\n",
       " (139, '2008'),\n",
       " (138, '45'),\n",
       " (138, '30000'),\n",
       " (135, 'voldemort'),\n",
       " (135, \"i'll\"),\n",
       " (135, \"china's\"),\n",
       " (134, '350'),\n",
       " (134, '\"what'),\n",
       " (133, 'vivekananda'),\n",
       " (133, 'aadhar'),\n",
       " (133, '70'),\n",
       " (133, '\"needs'),\n",
       " (131, 'kapil'),\n",
       " (131, \"country's\"),\n",
       " (130, 'oneplus'),\n",
       " (129, 'shippuden'),\n",
       " (129, '[/math]'),\n",
       " (128, 'programme'),\n",
       " (128, 'lyft'),\n",
       " (128, 'e-mail'),\n",
       " (126, 'srm'),\n",
       " (126, 'snowden'),\n",
       " (126, \"layman's\"),\n",
       " (126, 'improvement\"?'),\n",
       " (126, 'angularjs'),\n",
       " (126, '64'),\n",
       " (125, 'bitsat'),\n",
       " (125, '5000'),\n",
       " (125, '400'),\n",
       " (125, \"'\"),\n",
       " (124, 'trump’s'),\n",
       " (124, 'snapdeal'),\n",
       " (124, '1990'),\n",
       " (123, 'varanasi'),\n",
       " (122, '20k'),\n",
       " (121, 'kohli'),\n",
       " (121, 'cheque'),\n",
       " (121, 'amcat'),\n",
       " (120, 'pinterest'),\n",
       " (120, 'imessage'),\n",
       " (120, 'doesn’t'),\n",
       " (120, 'django'),\n",
       " (119, 'lumia'),\n",
       " (119, 'iisc'),\n",
       " (119, 'cancelled'),\n",
       " (118, 'ocd'),\n",
       " (118, \"girl's\"),\n",
       " (118, 'counselling'),\n",
       " (117, 'virat'),\n",
       " (117, 'fiitjee'),\n",
       " (117, 'defence'),\n",
       " (117, '80'),\n",
       " (116, 'little-known'),\n",
       " (116, 'bsnl'),\n",
       " (116, '90%'),\n",
       " (116, '$1000'),\n",
       " (115, 'year’s'),\n",
       " (115, 'courses:'),\n",
       " (115, '800'),\n",
       " (114, \"'the\"),\n",
       " (113, 'mca'),\n",
       " (113, 'gsoc'),\n",
       " (112, 't20'),\n",
       " (112, 'him/her'),\n",
       " (111, 'upvote'),\n",
       " (111, 'president-elect'),\n",
       " (111, 'bitcoins'),\n",
       " (111, 'aipmt'),\n",
       " (110, \"newton's\"),\n",
       " (110, 'correct:'),\n",
       " (110, '500/1000'),\n",
       " (109, 'clat'),\n",
       " (108, 'ratan'),\n",
       " (108, '04'),\n",
       " (107, '₹2000'),\n",
       " (107, 'ncert'),\n",
       " (107, 'learnt'),\n",
       " (107, '19th'),\n",
       " (106, '|'),\n",
       " (106, 'vladimir'),\n",
       " (106, '2007'),\n",
       " (105, 'indore'),\n",
       " (105, 'ex-girlfriend'),\n",
       " (105, 'advice:'),\n",
       " (104, 'long-term'),\n",
       " (104, 'delhi/ncr'),\n",
       " (103, 'micromax'),\n",
       " (103, 'dumbledore'),\n",
       " (103, 'dtu'),\n",
       " (103, \"apple's\"),\n",
       " (102, 'nagpur'),\n",
       " (101, 'iit-jee'),\n",
       " (100, 'ppf'),\n",
       " (100, 'behaviour'),\n",
       " (100, '\"no'),\n",
       " (99, \"venezuela's\"),\n",
       " (99, 'mckinsey'),\n",
       " (99, 'front-end'),\n",
       " (98, 'self-esteem'),\n",
       " (98, 'non-fiction'),\n",
       " (98, \"einstein's\"),\n",
       " (98, '50000'),\n",
       " (97, 'quora:'),\n",
       " (97, 'ktm'),\n",
       " (96, 'são'),\n",
       " (96, '[/math]?'),\n",
       " (96, '1/2'),\n",
       " (95, 'youtuber'),\n",
       " (95, 'viber'),\n",
       " (95, 'uan'),\n",
       " (95, 'tyres'),\n",
       " (95, 'ndtv'),\n",
       " (95, \"i'd\"),\n",
       " (95, '\"to'),\n",
       " (94, 'papua'),\n",
       " (94, 'ccna'),\n",
       " (94, 'bcom'),\n",
       " (94, '20000'),\n",
       " (93, 'llb'),\n",
       " (93, 'j7'),\n",
       " (93, 'dasht-e'),\n",
       " (93, 'capgemini'),\n",
       " (92, 'kitkat'),\n",
       " (92, 'bca'),\n",
       " (91, 'urjit'),\n",
       " (91, 'is/are'),\n",
       " (91, 'coimbatore'),\n",
       " (91, '52'),\n",
       " (90, 'tomé'),\n",
       " (90, 'príncipe'),\n",
       " (90, '.?'),\n",
       " (90, '$500'),\n",
       " (90, '\"needing'),\n",
       " (89, '”'),\n",
       " (89, 'you’re'),\n",
       " (89, 'lpa'),\n",
       " (89, \"girlfriend's\"),\n",
       " (89, \"company's\"),\n",
       " (89, '50%'),\n",
       " (89, '48'),\n",
       " (89, '31'),\n",
       " (89, '20th'),\n",
       " (88, 't-shirts'),\n",
       " (88, 'guatemala'),\n",
       " (87, 'zenfone'),\n",
       " (87, 'rna'),\n",
       " (87, 'nikola'),\n",
       " (87, 'jayalalitha'),\n",
       " (87, 'cut-off'),\n",
       " (87, 'centres'),\n",
       " (87, 'actor/actress'),\n",
       " (87, '250'),\n",
       " (87, '\"my'),\n",
       " (86, 'youtubers'),\n",
       " (86, 'xat'),\n",
       " (86, 'patanjali'),\n",
       " (86, 'kmc'),\n",
       " (86, 'colours'),\n",
       " (86, '()'),\n",
       " (85, 'yahoo!'),\n",
       " (85, 'labour'),\n",
       " (85, '3000'),\n",
       " (85, '\"in'),\n",
       " (85, '\"if'),\n",
       " (84, 'sonoran'),\n",
       " (84, 'hiroshima'),\n",
       " (84, 'designjet'),\n",
       " (83, 'intj'),\n",
       " (83, 'dangal'),\n",
       " (83, '75'),\n",
       " (83, '55'),\n",
       " (83, '40000'),\n",
       " (82, 'udemy'),\n",
       " (82, 'sheldon'),\n",
       " (81, 'vellore'),\n",
       " (81, 'mysore'),\n",
       " (81, 'bhagat'),\n",
       " (81, '180'),\n",
       " (81, '1080p'),\n",
       " (81, '10%'),\n",
       " (80, \"wife's\"),\n",
       " (80, 'question:'),\n",
       " (80, \"phone's\"),\n",
       " (80, 'otg'),\n",
       " (80, \"father's\"),\n",
       " (80, '120'),\n",
       " (80, '100k'),\n",
       " (80, '--'),\n",
       " (79, 'wbjee'),\n",
       " (79, \"rubik's\"),\n",
       " (79, 'non-profit'),\n",
       " (79, \"america's\"),\n",
       " (79, '\"i\\'m'),\n",
       " (78, 'spacex'),\n",
       " (78, 'part-time'),\n",
       " (78, 'improvement\"'),\n",
       " (78, \"california's\"),\n",
       " (78, '160'),\n",
       " (78, \"'s\"),\n",
       " (77, 'you’ve'),\n",
       " (77, \"writer's\"),\n",
       " (77, 'wars:'),\n",
       " (77, 't-shirt'),\n",
       " (77, 'selfie'),\n",
       " (77, 'organisation'),\n",
       " (77, 'high-end'),\n",
       " (77, 'all-time'),\n",
       " (76, \"mcdonald's\"),\n",
       " (76, 'kaif'),\n",
       " (76, 'jquery'),\n",
       " (76, '36'),\n",
       " (76, '2004'),\n",
       " (75, 'space-time'),\n",
       " (75, 'rukh'),\n",
       " (75, 'ramayana'),\n",
       " (75, 'full-time'),\n",
       " (75, \"asperger's\"),\n",
       " (74, 'melania'),\n",
       " (74, 'bhubaneswar'),\n",
       " (74, 'banglore'),\n",
       " (73, \"facebook's\"),\n",
       " (72, 'sa1'),\n",
       " (72, 'raghuram'),\n",
       " (72, 'nsit'),\n",
       " (72, 'granville'),\n",
       " (72, 'blockchain'),\n",
       " (72, 'ambani'),\n",
       " (72, '3-4'),\n",
       " (71, 'realise'),\n",
       " (71, 'bhim'),\n",
       " (71, \"amazon's\"),\n",
       " (71, '220'),\n",
       " (70, 'theatre'),\n",
       " (70, 'relationships:'),\n",
       " (70, 'object-oriented'),\n",
       " (70, 'mongolia'),\n",
       " (70, \"'empty'\"),\n",
       " (70, '\"thank'),\n",
       " (69, 'nagasaki'),\n",
       " (69, 'moocs'),\n",
       " (69, 'elitmus'),\n",
       " (69, '50ae'),\n",
       " (69, '25k'),\n",
       " (69, \"20's\"),\n",
       " (68, 'vishwanathan'),\n",
       " (68, 'psus'),\n",
       " (68, 'pgdm'),\n",
       " (68, 'miui'),\n",
       " (68, 'honours'),\n",
       " (67, 'ignou'),\n",
       " (67, '65'),\n",
       " (67, '33'),\n",
       " (66, 'mongodb'),\n",
       " (66, 'aleppo'),\n",
       " (66, '2006'),\n",
       " (66, '1tb'),\n",
       " (66, '00'),\n",
       " (66, '$50'),\n",
       " (65, 'oyo'),\n",
       " (65, 'ngc'),\n",
       " (65, 'must-read'),\n",
       " (65, 'laravel'),\n",
       " (65, 'gujarati'),\n",
       " (65, 'b1/b2'),\n",
       " (65, 'azhar'),\n",
       " (65, '40k'),\n",
       " (64, 'wharton'),\n",
       " (64, 'usmle'),\n",
       " (64, 'science:')]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_word_list[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate',\n",
       "       'question1_refine', 'question2_refine', 'q1_len', 'q2_len',\n",
       "       'q1_set_len', 'q2_set_len', 'common_len', 'common_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_refine</th>\n",
       "      <th>question2_refine</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_set_len</th>\n",
       "      <th>q2_set_len</th>\n",
       "      <th>common_len</th>\n",
       "      <th>common_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "\n",
       "                                    question1_refine  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                    question2_refine  q1_len  q2_len  \\\n",
       "0  What is the step by step guide to invest in sh...    14.0    12.0   \n",
       "\n",
       "   q1_set_len  q2_set_len  common_len  common_ratio  \n",
       "0        12.0        11.0        10.0      0.833333  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_all = train.drop(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate' ,'question1_refine', 'question2_refine'], axis=1)\n",
    "# X_all = StandardScaler().fit_transform(X_all)# doesn't work\n",
    "y_all = train.is_duplicate\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    # 自动设置的参数比简单自己调整的要效果好，这里没有做parameter tunning，因为这次实验的重点不在这\n",
    "#     'eta': 0.02, # learning rate\n",
    "#     'gamma': 0.01, # minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "#     'max_depth': 16, #maximum depth of a tree\n",
    "#     'min_child_weight': 1, #minimum sum of instance weight (hessian) needed in a child.\n",
    "#     'silent': 0, #0 means printing running messages, 1 means silent mode.\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X_all, label=y_all)\n",
    "\n",
    "# 等待early stopping\n",
    "history = xgb.cv(params, dtrain, num_boost_round=1024, early_stopping_rounds=5, verbose_eval=20)\n",
    "print(history.loc[history.shape[0]-1, ['test-logloss-mean', 'train-logloss-mean']])\n",
    "\n",
    "# Trial 1\n",
    "# init 0.492954\t\n",
    "# 符号分割: 0.508782 bad\n",
    "# 去掉符号: 0.514202 even bad\n",
    "# 2 grams: 0.502062 good\n",
    "# 3 grams: 0.499647 good\n",
    "\n",
    "# Trial 2\n",
    "# init 0.492954\n",
    "# 2 gram, 0.482699 good\n",
    "# 3 gram,0.480798 good\n",
    "# Start with: 0.444659 quite good\n",
    "# question_mark，bad\n",
    "\n",
    "# Trial 3\n",
    "# init, replace, 0.494482, bad, compared with Trial 1/2\n",
    "\n",
    "# Trial 4 \n",
    "# init, remove_mark: 0.514202, quite bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "booster = xgb.train(params, dtrain)\n",
    "xgb.plot_importance(booster=booster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.plot_tree(booster=booster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.to_graphviz(booster=booster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
